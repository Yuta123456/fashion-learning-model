{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datetime import datetime\n",
    "from models.ContrastiveLoss import ContrastiveLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # GPUデバイスを取得\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # CPUデバイスを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EmbeddingDataset('./data/anotation_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "learning_rate = 1e-5\n",
    "batch_size = 16\n",
    "epochs = 4\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "image_model = ImageEncoder(768).to(device)\n",
    "caption_model = CaptionEncoder().to(device)\n",
    "# image_model.load_state_dict(torch.load('model/model_image_2023-07-07.pth'))\n",
    "# caption_model.load_state_dict(torch.load('model/model_caption_2023-07-06.pth'))\n",
    "img_optimizer = torch.optim.Adam(image_model.parameters(), lr=learning_rate)\n",
    "cpt_optimizer = torch.optim.Adam(caption_model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = ContrastiveLoss()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, img_model, cpt_model,  loss_fn, img_opt, cpt_opt):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (img, cap, label, _) in enumerate(dataloader):        \n",
    "        # 予測と損失の計算\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        pred = img_model(img)\n",
    "        ids = tokenizer.batch_encode_plus(cap, return_tensors='pt', padding='max_length', truncation=True, max_length=256, add_special_tokens=True).input_ids\n",
    "        ids = ids.to(device)\n",
    "        target = cpt_model(ids)\n",
    "        # ここ不安\n",
    "        loss = loss_fn(pred, target, label)\n",
    "\n",
    "        # バックプロパゲーション\n",
    "        img_opt.zero_grad()\n",
    "        cpt_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        img_opt.step()\n",
    "        cpt_opt.step()\n",
    "\n",
    "        if batch % 30 == 0:\n",
    "            loss, current = loss.item() / len(img), batch * len(img)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        if batch % 1000 == 0:\n",
    "            # 現在の日付を取得します\n",
    "            now = datetime.now()\n",
    "\n",
    "            # YYYY-MM-DD形式で日付を出力します\n",
    "            formatted_date = now.strftime(\"%Y-%m-%d\")\n",
    "            torch.save(caption_model.state_dict(), f'model_caption_{formatted_date}.pth')\n",
    "            torch.save(image_model.state_dict(), f'model_image_{formatted_date}.pth')\n",
    "\n",
    "\n",
    "def test_loop(dataloader, img_model, cpt_model,  loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (img, cap, label, _) in dataloader:\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            pred = img_model(img)\n",
    "            ids = tokenizer.batch_encode_plus(cap, return_tensors='pt', padding='max_length', truncation=True, max_length=256, add_special_tokens=True).input_ids\n",
    "            ids = ids.to(device)\n",
    "            target = cpt_model(ids)\n",
    "            # print(pred.shape, target.shape, len(X), len(y))\n",
    "            # ここ不安\n",
    "            loss = loss_fn(pred, target, label).mean()\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start\")\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\-------------------------------\")\n",
    "    train_loop(train_dataloader, image_model, caption_model, loss_fn, img_optimizer, cpt_optimizer)\n",
    "    test_loop(test_dataloader, image_model, caption_model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tomotopy as tp\n",
    "import numpy as np\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LDA': tp.LDAModel,\n",
    "    'MGLDA': tp.MGLDAModel,\n",
    "    'CT': tp.CTModel,\n",
    "}\n",
    "model_params = {\n",
    "    'LDA': {\n",
    "        'tw': ['tw', 0, 2],\n",
    "        'k': ['k', 1, 10],\n",
    "        'alpha': ['alpha', 0.001, 0.05],\n",
    "        'eta': ['eta', 0.001, 0.05],\n",
    "    },\n",
    "    'CT': {\n",
    "        'tw': ['tw', 0, 2],\n",
    "        'k': ['k', 1, 10],\n",
    "        'smoothing_alpha': ['smoothing_alpha', 0.001, 0.05],\n",
    "        'eta': ['eta', 0.001, 0.05],\n",
    "    },\n",
    "    'MGLDA': {\n",
    "        'eta_g': ['eta_g', 0.001, 0.05],\n",
    "        'eta_l': ['eta_l', 0.001, 0.05],\n",
    "\n",
    "        'alpha_g': ['alpha_g', 0.001, 0.05],\n",
    "        'alpha_l': ['alpha_l', 0.001, 0.05],\n",
    "        'alpha_mg': ['alpha_mg', 0.001, 0.05],\n",
    "        'alpha_ml':['alpha_ml', 0.001, 0.05],\n",
    "        'gamma': ['gamma', 0.001, 0.05],\n",
    "\n",
    "        'k_g': ['k_g', 3, 10],\n",
    "        'k_l': ['k_l', 3, 10],\n",
    "        't': ['t', 1, 10],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "KIND = 'MGLDA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_trial(trial, p):\n",
    "    if type(p[1]) is int and type(p[2]) is int:\n",
    "        return trial.suggest_int(*p)\n",
    "    return trial.suggest_float(*p)\n",
    "\n",
    "class Objective:\n",
    "    def __init__(self, corpus):\n",
    "        # 変数X,yの初期化\n",
    "        self.corpus = corpus\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        # ハイパーパラメータの設定\n",
    "        params = {}\n",
    "        for key, p in model_params[KIND].items():\n",
    "            params[key] = to_trial(trial, p)\n",
    "        mdl = models[KIND](**params)\n",
    "        mdl.add_corpus(self.corpus)\n",
    "        mdl.train(1000)\n",
    "        # 評価指標として正解率の最大化を目指す\n",
    "        \n",
    "        return mdl.perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LDA\n"
     ]
    }
   ],
   "source": [
    "with open('C:/Users/yuuta/Documents/fashion/model_learning/topic_model/train_new.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    input_lines = f.read().splitlines()\n",
    "\n",
    "print('Running LDA')\n",
    "\n",
    "corpus = tp.utils.Corpus()\n",
    "for line in input_lines:\n",
    "    line = list(map(lambda x: x.strip(), line.split(',')))\n",
    "    corpus.add_doc(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-17 13:25:28,188] A new study created in memory with name: no-name-0a68f0c3-f98c-4d82-a577-d3dd0eaf2fde\n"
     ]
    }
   ],
   "source": [
    "objective = Objective(corpus)\n",
    "study = optuna.create_study(direction='minimize') # 最大化\n",
    "study.optimize(objective, timeout=7200 * 2)\n",
    "\n",
    "# ベストパラメータを出力\n",
    "print('params:', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(KIND, study.best_params)\n",
    "KIND = 'LDA'\n",
    "params = {'tw': 0, 'k': 4, 'alpha': 0.02566824950078614, 'eta': 0.04823495632461025}\n",
    "# mdl = models[KIND](**study.best_params)\n",
    "mdl = models[KIND](**params)\n",
    "mdl.add_corpus(corpus)\n",
    "mdl.train(1000)\n",
    "# MGLDAModel\n",
    "mdl.save('C:/Users/yuuta/Documents/fashion/model_learning/topic_model/models/' + f'{KIND}.bin', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words of topic #0\n",
      "[('tops_Silk', 0.08674614131450653), ('shoes_geo', 0.04992065578699112), ('tops_White', 0.04979587346315384), ('tops_plaintops_Silk', 0.049421526491642), ('shoes_plain', 0.04735894873738289), ('shoes_Black', 0.04284476116299629), ('tops_Beige', 0.03963711857795715), ('tops_Black', 0.03942425549030304), ('tops_plainshoes_Silk', 0.03416871279478073), ('tops_Gray', 0.026072537526488304)]\n",
      "Top 10 words of topic #1\n",
      "[('shoes_geo', 0.05843142047524452), ('tops_Silk', 0.05638058856129646), ('shoes_plain', 0.05298145115375519), ('shoes_Black', 0.04472843185067177), ('bottoms_Blue', 0.04367108270525932), ('tops_Denim', 0.03834174573421478), ('tops_plainbottoms_Silk', 0.02993970736861229), ('tops_Wool', 0.02986874431371689), ('tops_plainbottoms_Denim', 0.0291307270526886), ('tops_White', 0.0255825687199831)]\n",
      "Top 10 words of topic #2\n",
      "[('bottoms_Denim', 0.060762979090213776), ('bottoms_Silk', 0.05448056012392044), ('shoes_geo', 0.05190655216574669), ('bottoms_Blue', 0.04831906408071518), ('shoes_Black', 0.04000968486070633), ('shoes_plain', 0.03855280950665474), ('tops_White', 0.03422248736023903), ('tops_plainshoes_Silk', 0.024646257981657982), ('shoes_White', 0.023684604093432426), ('tops_plainshoes_Denim', 0.020482929423451424)]\n",
      "Top 10 words of topic #3\n",
      "[('tops_Blue', 0.08242126554250717), ('tops_Denim', 0.06577372550964355), ('shoes_geo', 0.06035405769944191), ('tops_Silk', 0.05679740011692047), ('shoes_Black', 0.04874759912490845), ('shoes_plain', 0.047263167798519135), ('tops_White', 0.0461672805249691), ('tops_Black', 0.04498172923922539), ('tops_Navy', 0.03255833685398102), ('shoes_White', 0.0281648188829422)]\n"
     ]
    }
   ],
   "source": [
    "for k in range(mdl.k):\n",
    "    print('Top 10 words of topic #{}'.format(k))\n",
    "    print(mdl.get_topic_words(k, top_n=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuuta\\anaconda3\\envs\\fashion\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\yuuta\\anaconda3\\envs\\fashion\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\yuuta\\anaconda3\\envs\\fashion\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "sys.path.append(\"C:/Users/yuuta/Documents/fashion\")\n",
    "from utils.util import filter_basic_items, open_json\n",
    "from utils.util import is_target_category\n",
    "from utils.util import calculate_euclid_sum\n",
    "# from utils.infer import id_to_vector\n",
    "from utils.util import calc_roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.util' from 'C:\\\\Users/yuuta/Documents/fashion\\\\utils\\\\util.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils.util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # GPUデバイスを取得\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # CPUデバイスを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_path = glob.glob(\n",
    "    \"C:/Users/yuuta/Documents/fashion/data/negative_coordinates/**.json\"\n",
    "    # \"C:/Users/yuuta/Documents/fashion/data/test/**/*.json\"\n",
    "    # negative_coordinates_random\n",
    ")\n",
    "positive_path = glob.glob(\n",
    "    \"C:/Users/yuuta/Documents/fashion/data/test/**/*.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 162975\n"
     ]
    }
   ],
   "source": [
    "print(len(negative_path), len(positive_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_vector = open_json('C:\\Users\\yuuta\\Documents/fashion\\model_learning\\compatibility\\data\\id_to_vector.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_path = random.sample(negative_path, 10000)\n",
    "positive_path = random.sample(positive_path, 10000)\n",
    "labels = []\n",
    "proposal_score = []\n",
    "positive_ave = 0\n",
    "negative_ave = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuuta\\AppData\\Local\\Temp\\ipykernel_15676\\1282012291.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  vectors.append(torch.tensor(vector))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive fin average: 38.85333251953125\n"
     ]
    }
   ],
   "source": [
    "from utils.util import calculate_euclid_max\n",
    "\n",
    "p_cnt = 0\n",
    "for fp in positive_path:\n",
    "    json_dict = open_json(fp)\n",
    "    items = filter_basic_items(json_dict[\"items\"])\n",
    "    attributes = []\n",
    "    vectors = []\n",
    "    for item in items:\n",
    "        try:\n",
    "            itemId = str(item[\"itemId\"])\n",
    "        except Exception as e:\n",
    "            print(fp, \" : \", e)\n",
    "            continue\n",
    "\n",
    "        vector = id_to_vector[itemId]\n",
    "        vectors.append(torch.tensor(vector))\n",
    "    if len(vectors) != 3:\n",
    "        continue\n",
    "    ps = calculate_euclid_max(vectors)\n",
    "    proposal_score.append(ps.to(\"cpu\"))\n",
    "    p_cnt += 1\n",
    "    labels.append(0)\n",
    "    positive_ave += ps\n",
    "    # if p_cnt > 5000:\n",
    "    #     break\n",
    "positive_ave /= p_cnt\n",
    "print(f\"positive fin average: {positive_ave}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuuta\\AppData\\Local\\Temp\\ipykernel_15676\\1794572436.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  vectors.append(torch.tensor(vector[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(38.8533, device='cuda:0') tensor(39.3007, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n_cnt = 0\n",
    "for fp in negative_path:\n",
    "    json_dict = open_json(fp)\n",
    "    if json_dict == None:\n",
    "        continue\n",
    "    parent_dir = os.path.dirname(fp)\n",
    "    items = []\n",
    "    attributes = []\n",
    "    vectors = []\n",
    "    for item in filter(is_target_category, json_dict[\"items\"]):\n",
    "        try:\n",
    "            itemId = str(item[\"itemId\"])\n",
    "        except Exception as e:\n",
    "            print(fp, \" : \", e)\n",
    "            continue\n",
    "\n",
    "        # vectorを推定\n",
    "        vector = id_to_vector[itemId]\n",
    "        vectors.append(torch.tensor(vector[0]))\n",
    "    if len(vectors) != 3:\n",
    "        continue\n",
    "    # print(len(vectors), vectors[0].shape)\n",
    "    ps = calculate_euclid_max(vectors)\n",
    "    proposal_score.append(ps.to(\"cpu\"))\n",
    "    labels.append(1)\n",
    "    n_cnt += 1\n",
    "    negative_ave += ps\n",
    "    # if n_cnt > 5000:\n",
    "    #     break\n",
    "negative_ave /= n_cnt\n",
    "\n",
    "print(positive_ave, negative_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5056 5056\n"
     ]
    }
   ],
   "source": [
    "print(len(proposal_score), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(64.2583),\n",
       " tensor(20.1430),\n",
       " tensor(10.4881),\n",
       " tensor(74.7889),\n",
       " tensor(36.1861),\n",
       " tensor(37.6088),\n",
       " tensor(25.5902),\n",
       " tensor(35.4634),\n",
       " tensor(30.0535),\n",
       " tensor(57.3306),\n",
       " tensor(28.5664),\n",
       " tensor(36.3760),\n",
       " tensor(77.3723),\n",
       " tensor(96.4543),\n",
       " tensor(66.2893),\n",
       " tensor(23.6048),\n",
       " tensor(30.8350),\n",
       " tensor(81.6939),\n",
       " tensor(40.6338),\n",
       " tensor(90.5582),\n",
       " tensor(25.5707),\n",
       " tensor(16.9242),\n",
       " tensor(40.9241),\n",
       " tensor(77.9107),\n",
       " tensor(23.4074),\n",
       " tensor(14.9488),\n",
       " tensor(23.1021),\n",
       " tensor(28.0073),\n",
       " tensor(22.3482),\n",
       " tensor(33.4833),\n",
       " tensor(17.7335),\n",
       " tensor(126.2882),\n",
       " tensor(31.3085),\n",
       " tensor(21.8429),\n",
       " tensor(9.0164),\n",
       " tensor(83.4901),\n",
       " tensor(11.0166),\n",
       " tensor(29.8413),\n",
       " tensor(17.5214),\n",
       " tensor(13.7336),\n",
       " tensor(31.5156),\n",
       " tensor(17.2425),\n",
       " tensor(21.8044),\n",
       " tensor(34.2694),\n",
       " tensor(43.6071),\n",
       " tensor(21.4757),\n",
       " tensor(71.5377),\n",
       " tensor(18.1140),\n",
       " tensor(23.5754),\n",
       " tensor(94.1354),\n",
       " tensor(20.9432),\n",
       " tensor(21.2036),\n",
       " tensor(11.5409),\n",
       " tensor(37.7046),\n",
       " tensor(35.5503),\n",
       " tensor(47.8819),\n",
       " tensor(26.5944),\n",
       " tensor(52.3218),\n",
       " tensor(24.7631),\n",
       " tensor(51.3120),\n",
       " tensor(25.0284),\n",
       " tensor(41.6282),\n",
       " tensor(8.4742),\n",
       " tensor(102.1107),\n",
       " tensor(108.5467),\n",
       " tensor(23.2270),\n",
       " tensor(32.8813),\n",
       " tensor(34.0251),\n",
       " tensor(40.8146),\n",
       " tensor(80.3785),\n",
       " tensor(21.6640),\n",
       " tensor(16.8880),\n",
       " tensor(27.0863),\n",
       " tensor(95.8660),\n",
       " tensor(11.8333),\n",
       " tensor(57.3340),\n",
       " tensor(55.4586),\n",
       " tensor(45.3053),\n",
       " tensor(42.1194),\n",
       " tensor(34.3287),\n",
       " tensor(15.8764),\n",
       " tensor(127.2888),\n",
       " tensor(30.7485),\n",
       " tensor(12.1424),\n",
       " tensor(44.2616),\n",
       " tensor(14.7721),\n",
       " tensor(25.0400),\n",
       " tensor(46.4220),\n",
       " tensor(36.4534),\n",
       " tensor(24.7785),\n",
       " tensor(17.9699),\n",
       " tensor(25.9573),\n",
       " tensor(17.2243),\n",
       " tensor(14.7872),\n",
       " tensor(23.3853),\n",
       " tensor(25.1421),\n",
       " tensor(11.7007),\n",
       " tensor(81.9155),\n",
       " tensor(30.3601),\n",
       " tensor(33.9308),\n",
       " tensor(13.7524),\n",
       " tensor(22.7405),\n",
       " tensor(12.9869),\n",
       " tensor(63.8571),\n",
       " tensor(67.3986),\n",
       " tensor(28.8301),\n",
       " tensor(15.9884),\n",
       " tensor(13.6814),\n",
       " tensor(46.5371),\n",
       " tensor(29.2140),\n",
       " tensor(33.9951),\n",
       " tensor(12.5827),\n",
       " tensor(151.1673),\n",
       " tensor(13.1136),\n",
       " tensor(31.5090),\n",
       " tensor(66.9310),\n",
       " tensor(8.1498),\n",
       " tensor(21.8555),\n",
       " tensor(16.7664),\n",
       " tensor(26.2470),\n",
       " tensor(11.1554),\n",
       " tensor(12.0466),\n",
       " tensor(121.9038),\n",
       " tensor(20.9796),\n",
       " tensor(39.5540),\n",
       " tensor(32.6493),\n",
       " tensor(74.8993),\n",
       " tensor(11.1985),\n",
       " tensor(26.8695),\n",
       " tensor(102.2033),\n",
       " tensor(63.4033),\n",
       " tensor(39.9035),\n",
       " tensor(21.4498),\n",
       " tensor(26.2035),\n",
       " tensor(82.3280),\n",
       " tensor(72.6925),\n",
       " tensor(92.1706),\n",
       " tensor(112.8208),\n",
       " tensor(69.2385),\n",
       " tensor(19.1120),\n",
       " tensor(79.1501),\n",
       " tensor(23.0466),\n",
       " tensor(48.8610),\n",
       " tensor(85.1572),\n",
       " tensor(48.5404),\n",
       " tensor(27.4575),\n",
       " tensor(93.5384),\n",
       " tensor(110.5324),\n",
       " tensor(14.7332),\n",
       " tensor(29.5514),\n",
       " tensor(7.8712),\n",
       " tensor(73.5198),\n",
       " tensor(27.2786),\n",
       " tensor(21.8850),\n",
       " tensor(166.0471),\n",
       " tensor(44.3373),\n",
       " tensor(12.7859),\n",
       " tensor(26.7743),\n",
       " tensor(19.6163),\n",
       " tensor(14.4530),\n",
       " tensor(18.8592),\n",
       " tensor(57.6853),\n",
       " tensor(27.6856),\n",
       " tensor(36.0658),\n",
       " tensor(42.5249),\n",
       " tensor(28.1444),\n",
       " tensor(34.5562),\n",
       " tensor(39.6273),\n",
       " tensor(87.6663),\n",
       " tensor(26.1211),\n",
       " tensor(11.2233),\n",
       " tensor(27.1157),\n",
       " tensor(21.7602),\n",
       " tensor(10.5554),\n",
       " tensor(54.9273),\n",
       " tensor(28.1582),\n",
       " tensor(8.2019),\n",
       " tensor(11.6389),\n",
       " tensor(28.6956),\n",
       " tensor(20.5374),\n",
       " tensor(141.3814),\n",
       " tensor(14.6995),\n",
       " tensor(34.5214),\n",
       " tensor(31.0748),\n",
       " tensor(40.7884),\n",
       " tensor(126.0506),\n",
       " tensor(11.1560),\n",
       " tensor(21.5175),\n",
       " tensor(20.7689),\n",
       " tensor(18.3786),\n",
       " tensor(49.3636),\n",
       " tensor(38.1368),\n",
       " tensor(28.2393),\n",
       " tensor(22.6382),\n",
       " tensor(46.0851),\n",
       " tensor(17.3836),\n",
       " tensor(34.4157),\n",
       " tensor(30.8010),\n",
       " tensor(11.2665),\n",
       " tensor(62.7490),\n",
       " tensor(25.7301),\n",
       " tensor(36.1189),\n",
       " tensor(23.2013),\n",
       " tensor(98.1399),\n",
       " tensor(18.9345),\n",
       " tensor(23.4633),\n",
       " tensor(14.1673),\n",
       " tensor(41.0251),\n",
       " tensor(104.4323),\n",
       " tensor(151.4673),\n",
       " tensor(31.8763),\n",
       " tensor(76.6176),\n",
       " tensor(26.2912),\n",
       " tensor(16.4667),\n",
       " tensor(32.5162),\n",
       " tensor(22.3412),\n",
       " tensor(16.8610),\n",
       " tensor(15.5179),\n",
       " tensor(30.9656),\n",
       " tensor(17.5728),\n",
       " tensor(19.4881),\n",
       " tensor(28.5475),\n",
       " tensor(38.3117),\n",
       " tensor(34.5245),\n",
       " tensor(90.4068),\n",
       " tensor(19.6297),\n",
       " tensor(31.0590),\n",
       " tensor(22.0742),\n",
       " tensor(12.3846),\n",
       " tensor(27.3144),\n",
       " tensor(43.4296),\n",
       " tensor(61.1589),\n",
       " tensor(20.0389),\n",
       " tensor(15.5922),\n",
       " tensor(12.6856),\n",
       " tensor(18.6631),\n",
       " tensor(32.4274),\n",
       " tensor(15.8684),\n",
       " tensor(24.7289),\n",
       " tensor(50.0616),\n",
       " tensor(26.9316),\n",
       " tensor(26.2137),\n",
       " tensor(67.0339),\n",
       " tensor(28.8236),\n",
       " tensor(38.0102),\n",
       " tensor(93.6636),\n",
       " tensor(30.8608),\n",
       " tensor(23.4895),\n",
       " tensor(30.8696),\n",
       " tensor(18.4505),\n",
       " tensor(11.6991),\n",
       " tensor(22.1203),\n",
       " tensor(41.5875),\n",
       " tensor(23.9632),\n",
       " tensor(59.5455),\n",
       " tensor(16.5946),\n",
       " tensor(31.0350),\n",
       " tensor(85.6121),\n",
       " tensor(14.0007),\n",
       " tensor(18.8008),\n",
       " tensor(23.0798),\n",
       " tensor(58.8048),\n",
       " tensor(54.3807),\n",
       " tensor(44.2771),\n",
       " tensor(10.4329),\n",
       " tensor(22.1005),\n",
       " tensor(39.2195),\n",
       " tensor(19.0305),\n",
       " tensor(90.0220),\n",
       " tensor(78.3785),\n",
       " tensor(33.3640),\n",
       " tensor(100.2071),\n",
       " tensor(10.5142),\n",
       " tensor(95.0335),\n",
       " tensor(73.0537),\n",
       " tensor(30.6012),\n",
       " tensor(15.3208),\n",
       " tensor(36.1180),\n",
       " tensor(7.5859),\n",
       " tensor(28.2928),\n",
       " tensor(31.9489),\n",
       " tensor(32.3951),\n",
       " tensor(13.7573),\n",
       " tensor(18.6401),\n",
       " tensor(30.8511),\n",
       " tensor(24.6147),\n",
       " tensor(24.8788),\n",
       " tensor(61.3331),\n",
       " tensor(81.0430),\n",
       " tensor(12.3081),\n",
       " tensor(27.8692),\n",
       " tensor(23.1901),\n",
       " tensor(56.0055),\n",
       " tensor(31.9563),\n",
       " tensor(7.7104),\n",
       " tensor(101.2523),\n",
       " tensor(35.7453),\n",
       " tensor(99.9047),\n",
       " tensor(27.7011),\n",
       " tensor(18.7786),\n",
       " tensor(165.8954),\n",
       " tensor(40.5738),\n",
       " tensor(25.0178),\n",
       " tensor(41.4973),\n",
       " tensor(33.4571),\n",
       " tensor(76.6951),\n",
       " tensor(13.9890),\n",
       " tensor(19.3383),\n",
       " tensor(61.5319),\n",
       " tensor(118.5503),\n",
       " tensor(16.5399),\n",
       " tensor(29.7019),\n",
       " tensor(27.8338),\n",
       " tensor(19.8676),\n",
       " tensor(46.6186),\n",
       " tensor(55.3667),\n",
       " tensor(10.4539),\n",
       " tensor(36.7464),\n",
       " tensor(21.4895),\n",
       " tensor(18.9986),\n",
       " tensor(19.8536),\n",
       " tensor(54.3574),\n",
       " tensor(78.7081),\n",
       " tensor(56.1183),\n",
       " tensor(66.1937),\n",
       " tensor(24.3402),\n",
       " tensor(19.6654),\n",
       " tensor(74.6962),\n",
       " tensor(46.8044),\n",
       " tensor(155.5906),\n",
       " tensor(35.1184),\n",
       " tensor(23.0212),\n",
       " tensor(30.9224),\n",
       " tensor(34.6102),\n",
       " tensor(37.6384),\n",
       " tensor(56.3003),\n",
       " tensor(28.7733),\n",
       " tensor(50.5436),\n",
       " tensor(19.5063),\n",
       " tensor(58.1507),\n",
       " tensor(22.1552),\n",
       " tensor(17.9711),\n",
       " tensor(29.5137),\n",
       " tensor(19.5628),\n",
       " tensor(17.6725),\n",
       " tensor(27.2400),\n",
       " tensor(21.9013),\n",
       " tensor(10.4995),\n",
       " tensor(27.6250),\n",
       " tensor(19.1579),\n",
       " tensor(13.4653),\n",
       " tensor(14.6671),\n",
       " tensor(25.5461),\n",
       " tensor(27.1226),\n",
       " tensor(32.3559),\n",
       " tensor(23.7037),\n",
       " tensor(36.1733),\n",
       " tensor(97.3220),\n",
       " tensor(93.5283),\n",
       " tensor(28.9504),\n",
       " tensor(24.2753),\n",
       " tensor(29.4925),\n",
       " tensor(35.7033),\n",
       " tensor(16.3743),\n",
       " tensor(26.3604),\n",
       " tensor(30.1274),\n",
       " tensor(115.0965),\n",
       " tensor(29.1817),\n",
       " tensor(25.0177),\n",
       " tensor(40.9337),\n",
       " tensor(17.1543),\n",
       " tensor(37.7049),\n",
       " tensor(29.6863),\n",
       " tensor(45.4434),\n",
       " tensor(21.2182),\n",
       " tensor(11.1841),\n",
       " tensor(18.5971),\n",
       " tensor(21.7870),\n",
       " tensor(33.0100),\n",
       " tensor(10.2490),\n",
       " tensor(25.4919),\n",
       " tensor(15.6176),\n",
       " tensor(31.3239),\n",
       " tensor(23.9233),\n",
       " tensor(110.5646),\n",
       " tensor(19.0034),\n",
       " tensor(15.4175),\n",
       " tensor(15.2928),\n",
       " tensor(46.5191),\n",
       " tensor(38.2237),\n",
       " tensor(89.7208),\n",
       " tensor(20.5653),\n",
       " tensor(12.8426),\n",
       " tensor(186.3319),\n",
       " tensor(20.7127),\n",
       " tensor(30.6468),\n",
       " tensor(20.5868),\n",
       " tensor(120.1145),\n",
       " tensor(29.0115),\n",
       " tensor(35.4636),\n",
       " tensor(29.4564),\n",
       " tensor(17.0864),\n",
       " tensor(13.1246),\n",
       " tensor(20.1003),\n",
       " tensor(26.4364),\n",
       " tensor(74.0898),\n",
       " tensor(7.3536),\n",
       " tensor(10.3093),\n",
       " tensor(23.2656),\n",
       " tensor(29.2448),\n",
       " tensor(32.6418),\n",
       " tensor(20.0656),\n",
       " tensor(22.2028),\n",
       " tensor(18.4234),\n",
       " tensor(40.3765),\n",
       " tensor(16.4196),\n",
       " tensor(17.1005),\n",
       " tensor(41.0416),\n",
       " tensor(7.7644),\n",
       " tensor(11.6009),\n",
       " tensor(27.8110),\n",
       " tensor(24.4445),\n",
       " tensor(16.1251),\n",
       " tensor(36.2130),\n",
       " tensor(59.8363),\n",
       " tensor(26.9542),\n",
       " tensor(36.9517),\n",
       " tensor(27.0820),\n",
       " tensor(10.2460),\n",
       " tensor(49.5382),\n",
       " tensor(32.3465),\n",
       " tensor(27.5676),\n",
       " tensor(18.6487),\n",
       " tensor(66.7981),\n",
       " tensor(16.6907),\n",
       " tensor(79.4767),\n",
       " tensor(28.2974),\n",
       " tensor(18.6100),\n",
       " tensor(21.3850),\n",
       " tensor(110.1670),\n",
       " tensor(101.4649),\n",
       " tensor(82.2240),\n",
       " tensor(20.8457),\n",
       " tensor(13.0431),\n",
       " tensor(16.4514),\n",
       " tensor(22.3138),\n",
       " tensor(37.4347),\n",
       " tensor(21.7387),\n",
       " tensor(17.8846),\n",
       " tensor(32.9747),\n",
       " tensor(19.6431),\n",
       " tensor(13.6379),\n",
       " tensor(77.0392),\n",
       " tensor(31.5715),\n",
       " tensor(40.8632),\n",
       " tensor(16.2131),\n",
       " tensor(9.7637),\n",
       " tensor(20.6495),\n",
       " tensor(39.5058),\n",
       " tensor(35.2439),\n",
       " tensor(16.5217),\n",
       " tensor(36.3310),\n",
       " tensor(26.8691),\n",
       " tensor(7.8267),\n",
       " tensor(40.4017),\n",
       " tensor(34.1254),\n",
       " tensor(47.9755),\n",
       " tensor(28.2433),\n",
       " tensor(33.3223),\n",
       " tensor(76.6340),\n",
       " tensor(15.7578),\n",
       " tensor(59.6179),\n",
       " tensor(49.6827),\n",
       " tensor(24.1589),\n",
       " tensor(33.1430),\n",
       " tensor(13.6275),\n",
       " tensor(74.3436),\n",
       " tensor(80.0281),\n",
       " tensor(57.2731),\n",
       " tensor(44.5784),\n",
       " tensor(25.5096),\n",
       " tensor(12.9730),\n",
       " tensor(18.5448),\n",
       " tensor(87.1091),\n",
       " tensor(18.0031),\n",
       " tensor(68.6629),\n",
       " tensor(87.1359),\n",
       " tensor(17.5425),\n",
       " tensor(22.7411),\n",
       " tensor(7.8117),\n",
       " tensor(13.3773),\n",
       " tensor(19.5010),\n",
       " tensor(32.1335),\n",
       " tensor(15.8212),\n",
       " tensor(9.1262),\n",
       " tensor(124.7458),\n",
       " tensor(20.7432),\n",
       " tensor(17.9008),\n",
       " tensor(146.7285),\n",
       " tensor(30.3653),\n",
       " tensor(22.3554),\n",
       " tensor(67.6641),\n",
       " tensor(128.6153),\n",
       " tensor(61.0485),\n",
       " tensor(64.8551),\n",
       " tensor(37.6952),\n",
       " tensor(30.3420),\n",
       " tensor(66.0166),\n",
       " tensor(26.0834),\n",
       " tensor(28.8758),\n",
       " tensor(21.7093),\n",
       " tensor(10.7005),\n",
       " tensor(43.1429),\n",
       " tensor(48.7926),\n",
       " tensor(12.3972),\n",
       " tensor(20.0926),\n",
       " tensor(46.9691),\n",
       " tensor(30.5552),\n",
       " tensor(59.0999),\n",
       " tensor(50.5896),\n",
       " tensor(39.1950),\n",
       " tensor(28.9198),\n",
       " tensor(9.9810),\n",
       " tensor(29.6918),\n",
       " tensor(34.5689),\n",
       " tensor(36.1819),\n",
       " tensor(24.1121),\n",
       " tensor(26.6120),\n",
       " tensor(18.2514),\n",
       " tensor(63.5751),\n",
       " tensor(13.1639),\n",
       " tensor(27.9037),\n",
       " tensor(65.8484),\n",
       " tensor(32.9045),\n",
       " tensor(22.2803),\n",
       " tensor(22.7680),\n",
       " tensor(10.7021),\n",
       " tensor(29.1082),\n",
       " tensor(40.5453),\n",
       " tensor(26.3514),\n",
       " tensor(21.6147),\n",
       " tensor(35.4413),\n",
       " tensor(12.1401),\n",
       " tensor(14.1283),\n",
       " tensor(77.7150),\n",
       " tensor(12.9263),\n",
       " tensor(40.4070),\n",
       " tensor(50.2610),\n",
       " tensor(36.5226),\n",
       " tensor(24.2109),\n",
       " tensor(45.4580),\n",
       " tensor(22.5368),\n",
       " tensor(33.6009),\n",
       " tensor(33.3175),\n",
       " tensor(24.6860),\n",
       " tensor(51.8647),\n",
       " tensor(30.4101),\n",
       " tensor(147.4928),\n",
       " tensor(35.0060),\n",
       " tensor(39.4003),\n",
       " tensor(22.7471),\n",
       " tensor(39.0668),\n",
       " tensor(62.8910),\n",
       " tensor(19.6905),\n",
       " tensor(16.0793),\n",
       " tensor(75.7901),\n",
       " tensor(36.1695),\n",
       " tensor(23.9464),\n",
       " tensor(52.2928),\n",
       " tensor(55.0563),\n",
       " tensor(40.7622),\n",
       " tensor(19.2196),\n",
       " tensor(121.2617),\n",
       " tensor(31.9768),\n",
       " tensor(19.2623),\n",
       " tensor(90.9298),\n",
       " tensor(33.0419),\n",
       " tensor(37.6625),\n",
       " tensor(163.7971),\n",
       " tensor(50.0037),\n",
       " tensor(16.6382),\n",
       " tensor(11.8854),\n",
       " tensor(26.2678),\n",
       " tensor(61.9171),\n",
       " tensor(27.9638),\n",
       " tensor(28.3619),\n",
       " tensor(100.2469),\n",
       " tensor(7.9863),\n",
       " tensor(17.1452),\n",
       " tensor(37.4120),\n",
       " tensor(32.8145),\n",
       " tensor(70.0841),\n",
       " tensor(40.6208),\n",
       " tensor(118.6722),\n",
       " tensor(22.6693),\n",
       " tensor(18.9737),\n",
       " tensor(92.9487),\n",
       " tensor(35.1561),\n",
       " tensor(92.8719),\n",
       " tensor(32.4475),\n",
       " tensor(100.0626),\n",
       " tensor(33.6418),\n",
       " tensor(43.8866),\n",
       " tensor(28.8261),\n",
       " tensor(30.0865),\n",
       " tensor(18.2809),\n",
       " tensor(46.0533),\n",
       " tensor(33.5396),\n",
       " tensor(36.3084),\n",
       " tensor(26.3020),\n",
       " tensor(111.5980),\n",
       " tensor(23.0734),\n",
       " tensor(52.2898),\n",
       " tensor(11.6594),\n",
       " tensor(51.6006),\n",
       " tensor(11.2671),\n",
       " tensor(73.5521),\n",
       " tensor(25.8090),\n",
       " tensor(52.6776),\n",
       " tensor(12.5448),\n",
       " tensor(63.2175),\n",
       " tensor(166.0859),\n",
       " tensor(98.5591),\n",
       " tensor(20.7563),\n",
       " tensor(18.9304),\n",
       " tensor(103.1820),\n",
       " tensor(25.4935),\n",
       " tensor(40.8852),\n",
       " tensor(71.3981),\n",
       " tensor(22.2161),\n",
       " tensor(21.3377),\n",
       " tensor(23.8761),\n",
       " tensor(43.3498),\n",
       " tensor(21.6306),\n",
       " tensor(92.3027),\n",
       " tensor(12.4417),\n",
       " tensor(226.1128),\n",
       " tensor(24.0638),\n",
       " tensor(110.7112),\n",
       " tensor(30.8643),\n",
       " tensor(38.8246),\n",
       " tensor(35.1443),\n",
       " tensor(23.6964),\n",
       " tensor(39.3985),\n",
       " tensor(42.2196),\n",
       " tensor(27.6095),\n",
       " tensor(12.8675),\n",
       " tensor(17.2923),\n",
       " tensor(52.2008),\n",
       " tensor(44.4651),\n",
       " tensor(79.6452),\n",
       " tensor(40.3727),\n",
       " tensor(33.6177),\n",
       " tensor(59.5411),\n",
       " tensor(136.3103),\n",
       " tensor(40.4502),\n",
       " tensor(22.4076),\n",
       " tensor(60.0572),\n",
       " tensor(19.6154),\n",
       " tensor(59.6726),\n",
       " tensor(13.4693),\n",
       " tensor(12.9854),\n",
       " tensor(18.7652),\n",
       " tensor(87.9913),\n",
       " tensor(14.5976),\n",
       " tensor(73.6719),\n",
       " tensor(25.5567),\n",
       " tensor(32.9032),\n",
       " tensor(97.8109),\n",
       " tensor(28.2757),\n",
       " tensor(92.2397),\n",
       " tensor(44.3203),\n",
       " tensor(112.4634),\n",
       " tensor(24.3821),\n",
       " tensor(7.2940),\n",
       " tensor(35.3154),\n",
       " tensor(22.3202),\n",
       " tensor(31.3270),\n",
       " tensor(11.1733),\n",
       " tensor(25.5205),\n",
       " tensor(25.9248),\n",
       " tensor(37.0075),\n",
       " tensor(17.8559),\n",
       " tensor(12.0626),\n",
       " tensor(19.5316),\n",
       " tensor(18.7432),\n",
       " tensor(33.4308),\n",
       " tensor(19.3807),\n",
       " tensor(33.0086),\n",
       " tensor(121.4769),\n",
       " tensor(25.0799),\n",
       " tensor(20.3711),\n",
       " tensor(18.1377),\n",
       " tensor(17.5709),\n",
       " tensor(51.7809),\n",
       " tensor(13.3579),\n",
       " tensor(34.4840),\n",
       " tensor(20.7525),\n",
       " tensor(30.7463),\n",
       " tensor(73.2347),\n",
       " tensor(58.9929),\n",
       " tensor(19.0098),\n",
       " tensor(22.3742),\n",
       " tensor(24.6693),\n",
       " tensor(10.0816),\n",
       " tensor(44.0641),\n",
       " tensor(16.0189),\n",
       " tensor(20.6808),\n",
       " tensor(12.1229),\n",
       " tensor(37.8841),\n",
       " tensor(9.6937),\n",
       " tensor(10.2393),\n",
       " tensor(20.1851),\n",
       " tensor(25.3240),\n",
       " tensor(24.0949),\n",
       " tensor(7.6748),\n",
       " tensor(68.3636),\n",
       " tensor(15.3432),\n",
       " tensor(86.6848),\n",
       " tensor(29.7646),\n",
       " tensor(68.9574),\n",
       " tensor(110.8175),\n",
       " tensor(107.5584),\n",
       " tensor(44.8782),\n",
       " tensor(13.0112),\n",
       " tensor(22.1712),\n",
       " tensor(23.9498),\n",
       " tensor(11.5132),\n",
       " tensor(42.8440),\n",
       " tensor(23.1869),\n",
       " tensor(78.0224),\n",
       " tensor(13.5238),\n",
       " tensor(27.9029),\n",
       " tensor(23.2222),\n",
       " tensor(29.5045),\n",
       " tensor(24.8355),\n",
       " tensor(39.1480),\n",
       " tensor(29.3172),\n",
       " tensor(95.1526),\n",
       " tensor(31.6122),\n",
       " tensor(15.6284),\n",
       " tensor(33.8381),\n",
       " tensor(103.0859),\n",
       " tensor(28.4217),\n",
       " tensor(38.1133),\n",
       " tensor(39.4388),\n",
       " tensor(69.2228),\n",
       " tensor(26.7163),\n",
       " tensor(29.8350),\n",
       " tensor(70.6196),\n",
       " tensor(22.6810),\n",
       " tensor(66.4898),\n",
       " tensor(73.7204),\n",
       " tensor(114.2512),\n",
       " tensor(33.0831),\n",
       " tensor(18.7299),\n",
       " tensor(41.9608),\n",
       " tensor(52.9498),\n",
       " tensor(16.1414),\n",
       " tensor(17.0600),\n",
       " tensor(18.2951),\n",
       " tensor(85.7915),\n",
       " tensor(22.6629),\n",
       " tensor(29.8859),\n",
       " tensor(29.5574),\n",
       " tensor(24.9877),\n",
       " tensor(66.7377),\n",
       " tensor(26.5691),\n",
       " tensor(12.3976),\n",
       " tensor(18.8841),\n",
       " tensor(26.8961),\n",
       " tensor(71.6188),\n",
       " tensor(31.8541),\n",
       " tensor(34.7160),\n",
       " tensor(9.4940),\n",
       " tensor(35.8513),\n",
       " tensor(18.8955),\n",
       " tensor(108.8239),\n",
       " tensor(7.2554),\n",
       " tensor(113.4653),\n",
       " tensor(29.0941),\n",
       " tensor(43.9476),\n",
       " tensor(11.8178),\n",
       " tensor(11.1605),\n",
       " tensor(12.4374),\n",
       " tensor(27.6711),\n",
       " tensor(26.5700),\n",
       " tensor(30.8928),\n",
       " tensor(35.0109),\n",
       " tensor(29.4438),\n",
       " tensor(75.8295),\n",
       " tensor(18.4368),\n",
       " tensor(39.0280),\n",
       " tensor(36.2314),\n",
       " tensor(57.1534),\n",
       " tensor(15.2560),\n",
       " tensor(46.7447),\n",
       " tensor(90.1888),\n",
       " tensor(72.9306),\n",
       " tensor(16.6741),\n",
       " tensor(74.2343),\n",
       " tensor(56.8847),\n",
       " tensor(22.0131),\n",
       " tensor(31.0444),\n",
       " tensor(61.9602),\n",
       " tensor(22.9515),\n",
       " tensor(21.8855),\n",
       " tensor(11.6341),\n",
       " tensor(25.5744),\n",
       " tensor(15.0548),\n",
       " tensor(24.9026),\n",
       " tensor(30.9382),\n",
       " tensor(30.3973),\n",
       " tensor(28.5368),\n",
       " tensor(62.8684),\n",
       " tensor(13.1708),\n",
       " tensor(16.7624),\n",
       " tensor(61.9354),\n",
       " tensor(32.2418),\n",
       " tensor(71.8170),\n",
       " tensor(57.2870),\n",
       " tensor(28.7531),\n",
       " tensor(8.7178),\n",
       " tensor(13.6457),\n",
       " tensor(32.7136),\n",
       " tensor(9.5416),\n",
       " tensor(35.6570),\n",
       " tensor(14.8013),\n",
       " tensor(18.7314),\n",
       " tensor(18.1968),\n",
       " tensor(57.1910),\n",
       " tensor(43.4928),\n",
       " tensor(124.7585),\n",
       " tensor(88.3612),\n",
       " tensor(63.4906),\n",
       " tensor(10.6482),\n",
       " tensor(26.4669),\n",
       " tensor(53.3056),\n",
       " tensor(48.4447),\n",
       " tensor(13.7267),\n",
       " tensor(23.9772),\n",
       " tensor(58.2828),\n",
       " tensor(18.2480),\n",
       " tensor(37.5068),\n",
       " tensor(39.3027),\n",
       " tensor(28.9865),\n",
       " tensor(19.9236),\n",
       " tensor(24.5333),\n",
       " tensor(53.0943),\n",
       " tensor(89.0411),\n",
       " tensor(13.2525),\n",
       " tensor(61.0672),\n",
       " tensor(30.4489),\n",
       " tensor(18.0867),\n",
       " tensor(19.8523),\n",
       " tensor(189.3441),\n",
       " tensor(43.3072),\n",
       " tensor(23.5609),\n",
       " tensor(72.9174),\n",
       " tensor(28.9418),\n",
       " tensor(49.7095),\n",
       " tensor(86.6395),\n",
       " tensor(31.9134),\n",
       " tensor(64.9541),\n",
       " tensor(17.1237),\n",
       " tensor(60.1193),\n",
       " tensor(126.5296),\n",
       " tensor(43.4593),\n",
       " tensor(20.3403),\n",
       " tensor(28.9874),\n",
       " tensor(62.7618),\n",
       " tensor(34.3054),\n",
       " tensor(29.5097),\n",
       " tensor(23.9989),\n",
       " tensor(22.3734),\n",
       " tensor(41.2742),\n",
       " tensor(19.3560),\n",
       " tensor(23.7753),\n",
       " tensor(25.0651),\n",
       " tensor(37.3603),\n",
       " tensor(22.7798),\n",
       " tensor(31.8191),\n",
       " tensor(50.4113),\n",
       " tensor(58.0756),\n",
       " tensor(20.4128),\n",
       " tensor(20.5745),\n",
       " tensor(84.5350),\n",
       " tensor(59.2495),\n",
       " tensor(77.0130),\n",
       " tensor(17.7459),\n",
       " tensor(31.5949),\n",
       " tensor(14.5592),\n",
       " tensor(25.1316),\n",
       " tensor(26.8088),\n",
       " tensor(36.6830),\n",
       " tensor(23.1772),\n",
       " tensor(19.1790),\n",
       " tensor(117.8151),\n",
       " tensor(46.2610),\n",
       " tensor(37.3886),\n",
       " tensor(18.9790),\n",
       " tensor(56.0980),\n",
       " tensor(24.8002),\n",
       " tensor(45.5447),\n",
       " tensor(53.9328),\n",
       " tensor(58.2432),\n",
       " tensor(77.1318),\n",
       " tensor(32.3528),\n",
       " tensor(86.8486),\n",
       " tensor(28.7124),\n",
       " tensor(142.5767),\n",
       " tensor(116.4312),\n",
       " tensor(34.9210),\n",
       " tensor(55.5030),\n",
       " tensor(22.9266),\n",
       " tensor(16.5002),\n",
       " tensor(22.4689),\n",
       " tensor(130.5118),\n",
       " tensor(10.9896),\n",
       " tensor(68.6512),\n",
       " tensor(61.7494),\n",
       " tensor(19.4060),\n",
       " tensor(50.5957),\n",
       " tensor(80.7323),\n",
       " tensor(13.5935),\n",
       " tensor(25.3479),\n",
       " tensor(14.9148),\n",
       " tensor(18.8678),\n",
       " tensor(11.5707),\n",
       " tensor(58.6072),\n",
       " tensor(129.8147),\n",
       " tensor(28.4406),\n",
       " tensor(74.9923),\n",
       " tensor(24.2595),\n",
       " tensor(16.2709),\n",
       " tensor(64.0337),\n",
       " tensor(14.9248),\n",
       " tensor(73.9507),\n",
       " tensor(12.7184),\n",
       " tensor(38.0999),\n",
       " tensor(28.6509),\n",
       " tensor(19.5531),\n",
       " tensor(22.6100),\n",
       " tensor(51.1147),\n",
       " tensor(61.6869),\n",
       " tensor(16.5256),\n",
       " tensor(39.7500),\n",
       " tensor(28.2859),\n",
       " tensor(64.6511),\n",
       " tensor(91.2593),\n",
       " tensor(8.6722),\n",
       " tensor(18.9691),\n",
       " tensor(28.6467),\n",
       " tensor(32.5360),\n",
       " tensor(55.7849),\n",
       " tensor(32.0721),\n",
       " tensor(27.7908),\n",
       " tensor(41.5679),\n",
       " tensor(14.1189),\n",
       " tensor(38.9946),\n",
       " tensor(33.8885),\n",
       " tensor(27.2832),\n",
       " tensor(27.3690),\n",
       " tensor(36.7683),\n",
       " tensor(20.8815),\n",
       " tensor(61.1460),\n",
       " tensor(24.1820),\n",
       " tensor(34.4046),\n",
       " tensor(52.3748),\n",
       " tensor(37.0799),\n",
       " tensor(14.0712),\n",
       " tensor(58.2874),\n",
       " tensor(7.0788),\n",
       " tensor(17.4519),\n",
       " tensor(121.0119),\n",
       " tensor(24.6192),\n",
       " tensor(23.7436),\n",
       " tensor(50.8800),\n",
       " tensor(28.8235),\n",
       " tensor(26.1277),\n",
       " tensor(17.0938),\n",
       " tensor(10.9945),\n",
       " tensor(17.4875),\n",
       " tensor(52.5647),\n",
       " tensor(25.2061),\n",
       " tensor(10.6258),\n",
       " tensor(56.4514),\n",
       " tensor(28.6281),\n",
       " tensor(15.8791),\n",
       " tensor(61.4188),\n",
       " tensor(24.7542),\n",
       " tensor(27.2388),\n",
       " tensor(29.5095),\n",
       " tensor(17.8549),\n",
       " tensor(50.4005),\n",
       " tensor(50.6930),\n",
       " tensor(15.4650),\n",
       " tensor(17.2625),\n",
       " tensor(28.6955),\n",
       " tensor(19.9325),\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m p_auc \u001b[38;5;241m=\u001b[39m calc_roc_auc(labels, \u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproposal_score\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproposal_model_image_only\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(p_auc)\n",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m p_auc \u001b[38;5;241m=\u001b[39m calc_roc_auc(labels, [\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m proposal_score], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproposal_model_image_only\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(p_auc)\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "p_auc = calc_roc_auc(labels, [p[0] for p in proposal_score], \"proposal_model_image_only\")\n",
    "print(p_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5551839062628233\n"
     ]
    }
   ],
   "source": [
    "print(p_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m difference_vector \u001b[38;5;241m=\u001b[39m anchor_vector \u001b[38;5;241m-\u001b[39m positive_vector\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# ノルムを計算\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m norm_result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdifference_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(norm_result\u001b[38;5;241m.\u001b[39mitem())  \u001b[38;5;66;03m# 結果を取得して表示\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yuuta\\anaconda3\\envs\\fashion\\Lib\\site-packages\\torch\\functional.py:1595\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[0;32m   1593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dim, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dim) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1597\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m2\u001b[39m, _dim, keepdim, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 仮のベクトルを定義\n",
    "anchor_vector = torch.tensor([1.0, 2.0, 3.0])\n",
    "positive_vector = torch.tensor([2.0, 3.0, 4.0])\n",
    "\n",
    "# ベクトルの差を計算\n",
    "difference_vector = anchor_vector - positive_vector\n",
    "\n",
    "# ノルムを計算\n",
    "norm_result = torch.norm(difference_vector, dim=1)\n",
    "\n",
    "print(norm_result.item())  # 結果を取得して表示"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
